{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlFQXu6h5zfKgdigYK+mqj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saibaddala/DL_Assignment_1/blob/main/DL_Assignment_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gozsKq6FKAUQ"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from keras.datasets import fashion_mnist\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import wandb\n",
        "\n",
        "# End any open wandb sessions\n",
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def acquire_fashion_mnist_data():\n",
        "    \"\"\"\n",
        "    Fetch Fashion MNIST, returning (train_imgs, train_lbls) and (test_imgs, test_lbls),\n",
        "    plus a sample set containing one image for each label.\n",
        "    \"\"\"\n",
        "    (train_imgs, train_lbls), (test_imgs, test_lbls) = fashion_mnist.load_data()\n",
        "\n",
        "    unique_tracker = np.unique(train_lbls)\n",
        "    sample_collection = []\n",
        "\n",
        "    # Pick one sample image per class\n",
        "    for im, lab in zip(train_imgs, train_lbls):\n",
        "        if lab in unique_tracker:\n",
        "            sample_collection.append(im)\n",
        "            location = np.where(unique_tracker == lab)\n",
        "            unique_tracker = np.delete(unique_tracker, location)\n",
        "        if len(unique_tracker) == 0:\n",
        "            break\n",
        "\n",
        "    return (train_imgs, train_lbls), (test_imgs, test_lbls), sample_collection"
      ],
      "metadata": {
        "id": "3_P0G4hkKvdG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(tr_images, tr_labels, ts_images, ts_labels, ratio=0.9):\n",
        "    \"\"\"\n",
        "    Flatten 28x28 images into 1D, normalize pixel values, and split training\n",
        "    into train and validation sets according to ratio.\n",
        "    \"\"\"\n",
        "    total_train_count = len(tr_images)\n",
        "    valid_start_index = int(total_train_count * ratio)\n",
        "\n",
        "    all_flat_train = []\n",
        "    for i in range(total_train_count):\n",
        "        flat_image = tr_images[i].reshape(-1) / 255.0\n",
        "        all_flat_train.append(flat_image)\n",
        "\n",
        "    all_flat_test = []\n",
        "    for j in range(len(ts_images)):\n",
        "        flattened_test = ts_images[j].flatten() / 255.0\n",
        "        all_flat_test.append(flattened_test)\n",
        "\n",
        "    xtrain = np.array(all_flat_train[:valid_start_index])\n",
        "    ytrain = tr_labels[:valid_start_index]\n",
        "    xval   = np.array(all_flat_train[valid_start_index:])\n",
        "    yval   = tr_labels[valid_start_index:]\n",
        "    xtest  = np.array(all_flat_test)\n",
        "    ytest  = ts_labels\n",
        "\n",
        "    return xtrain, ytrain, xval, yval, xtest, ytest"
      ],
      "metadata": {
        "id": "TRSOZigpK1pF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_class_samples(sample_pics, label_names):\n",
        "    \"\"\"\n",
        "    Plot sample images (one per class) and log the figure to W&B.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    ax_count = 2 * 5  # 2 rows, 5 cols\n",
        "\n",
        "    for idx in range(ax_count):\n",
        "        subp = fig.add_subplot(2, 5, idx + 1)\n",
        "        subp.imshow(sample_pics[idx], cmap='binary')\n",
        "        subp.set_title(label_names[idx])\n",
        "        subp.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('class_examples.png')\n",
        "\n",
        "    wandb.login()\n",
        "    wandb.init(project='DL assignment 1')\n",
        "    wandb.log({\"sample_images\": wandb.Image('class_examples.png')})\n",
        "\n",
        "    plt.show()\n",
        "    wandb.finish()"
      ],
      "metadata": {
        "id": "2mAKJYFeK9YY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "    \"\"\"\n",
        "    A multi-layer neural network with flexible initialization, activations,\n",
        "    optimizers, and loss functions.\n",
        "    \"\"\"\n",
        "    def __init__(self, input_size, num_outputs, cfg):\n",
        "        self.in_features   = input_size\n",
        "        self.out_features  = num_outputs\n",
        "        self.hidden_count  = cfg[\"hidden_layers\"]\n",
        "        self.hidden_dim    = cfg[\"hl_size\"]\n",
        "        self.total_layers  = self.hidden_count + 1\n",
        "\n",
        "        self.init_approach  = cfg[\"initialization\"]\n",
        "        self.activ_method   = cfg[\"activation\"]\n",
        "        self.loss_mech      = cfg[\"loss\"]\n",
        "        self.optimizer_kind = cfg[\"optimizer\"]\n",
        "        self.lr             = cfg[\"learning_rate\"]\n",
        "        self.weight_decay   = cfg[\"weight_decay\"]\n",
        "        self.batch_size     = cfg[\"batch_size\"]\n",
        "        self.epochs         = cfg[\"epochs\"]\n",
        "\n",
        "        self.momentum_factor = cfg.get(\"momentum_beta\", 0.9)\n",
        "        self.rms_factor      = cfg.get(\"rms_beta\", 0.5)\n",
        "        self.adam_beta1      = cfg.get(\"beta1\", 0.9)\n",
        "        self.adam_beta2      = cfg.get(\"beta2\", 0.9)\n",
        "        self.epsilon_adam    = cfg.get(\"eps\", 1e-8)\n",
        "\n",
        "        self.W_matrices = []\n",
        "        self.B_vectors  = []\n",
        "\n",
        "        self._prepare_parameters()\n",
        "\n",
        "    def _prepare_parameters(self):\n",
        "        for i in range(self.total_layers):\n",
        "            if i == 0:\n",
        "                in_dim = self.in_features\n",
        "                out_dim = self.hidden_dim\n",
        "            elif i == self.total_layers - 1:\n",
        "                in_dim = self.hidden_dim\n",
        "                out_dim = self.out_features\n",
        "            else:\n",
        "                in_dim = self.hidden_dim\n",
        "                out_dim = self.hidden_dim\n",
        "\n",
        "            if self.init_approach == \"random\":\n",
        "                W_temp = np.random.randn(out_dim, in_dim) * 0.01\n",
        "                B_temp = np.random.randn(out_dim, 1) * 0.01\n",
        "            else:  # Xavier\n",
        "                scale_factor = np.sqrt(2.0 / (in_dim + out_dim))\n",
        "                W_temp = np.random.randn(out_dim, in_dim) * scale_factor\n",
        "                B_temp = np.zeros((out_dim, 1))\n",
        "\n",
        "            self.W_matrices.append(W_temp)\n",
        "            self.B_vectors.append(B_temp)\n",
        "\n",
        "    def feed_forward_neural_net(self, single_input):\n",
        "        \"\"\"\n",
        "        Forward pass for one sample:\n",
        "        returns (layer_outputs, pre_activation_values).\n",
        "        \"\"\"\n",
        "        layer_outputs   = [None] * self.total_layers\n",
        "        pre_activations = [None] * self.total_layers\n",
        "        current_act     = single_input.reshape(-1, 1)\n",
        "\n",
        "        for idx in range(self.total_layers):\n",
        "            z_val = np.dot(self.W_matrices[idx], current_act) + self.B_vectors[idx]\n",
        "            pre_activations[idx] = z_val\n",
        "\n",
        "            if idx == self.total_layers - 1:\n",
        "                out_val = self._softmax(z_val)\n",
        "            else:\n",
        "                out_val = self._apply_activation(self.activ_method, z_val)\n",
        "\n",
        "            layer_outputs[idx] = out_val\n",
        "            current_act = out_val\n",
        "\n",
        "        return layer_outputs, pre_activations\n",
        "\n",
        "    def backward_eval(self, layer_outputs, pre_acts, true_label, x_vec):\n",
        "        \"\"\"\n",
        "        Backprop for one sample. Returns gradients for each layer's weights and biases.\n",
        "        \"\"\"\n",
        "        grad_weights = [np.zeros_like(wi) for wi in self.W_matrices]\n",
        "        grad_biases  = [np.zeros_like(bi) for bi in self.B_vectors]\n",
        "\n",
        "        # One-hot target\n",
        "        y_one_hot = np.zeros((self.out_features, 1))\n",
        "        y_one_hot[true_label] = 1\n",
        "\n",
        "        # Final layer derivative depends on loss\n",
        "        if self.loss_mech == \"cross_entropy\":\n",
        "            dz_final = (layer_outputs[-1] - y_one_hot)\n",
        "        else:  # MSE\n",
        "            diff = layer_outputs[-1] - y_one_hot\n",
        "            dz_final = diff * (layer_outputs[-1] * (1 - layer_outputs[-1]))\n",
        "\n",
        "        dz_vals = [None] * self.total_layers\n",
        "        dz_vals[self.total_layers - 1] = dz_final\n",
        "\n",
        "        for i in range(self.total_layers - 1, -1, -1):\n",
        "            if i == 0:\n",
        "                input_vec = x_vec.reshape(1, -1)\n",
        "            else:\n",
        "                input_vec = layer_outputs[i - 1].T\n",
        "\n",
        "            grad_weights[i] = np.dot(dz_vals[i], input_vec)\n",
        "            grad_biases[i]  = dz_vals[i]\n",
        "\n",
        "            if i > 0:\n",
        "                up_val = np.dot(self.W_matrices[i].T, dz_vals[i])\n",
        "                dz_vals[i - 1] = up_val * self._activate_derivative(self.activ_method, pre_acts[i - 1])\n",
        "\n",
        "        return grad_weights, grad_biases\n",
        "\n",
        "    def training(self, x_train, y_train, x_val, y_val):\n",
        "        \"\"\"\n",
        "        Trains using whichever optimizer is set in the config.\n",
        "        \"\"\"\n",
        "        opt = self.optimizer_kind\n",
        "        if opt == \"sgd\":\n",
        "            self.sgd_optimizer(x_train, y_train, x_val, y_val)\n",
        "        elif opt == \"momentum\":\n",
        "            self.momentum_optimizer(x_train, y_train, x_val, y_val)\n",
        "        elif opt == \"nestrov\":\n",
        "            self.nesterov_optimizer(x_train, y_train, x_val, y_val)\n",
        "        elif opt == \"rmsprop\":\n",
        "            self.rmsprop_optimizer(x_train, y_train, x_val, y_val)\n",
        "        elif opt == \"adam\":\n",
        "            self.adam_optimizer(x_train, y_train, x_val, y_val)\n",
        "        elif opt == \"nadam\":\n",
        "            self.nadam_optimizer(x_train, y_train, x_val, y_val)\n",
        "\n",
        "    def sgd_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        Simple SGD with optional L2 regularization.\n",
        "        \"\"\"\n",
        "        total_data = len(xT)\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for start in range(0, total_data, self.batch_size):\n",
        "                end = start + self.batch_size\n",
        "                x_batch = xT[start:end]\n",
        "                y_batch = yT[start:end]\n",
        "\n",
        "                dw_acc = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                db_acc = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for i_sample in range(len(x_batch)):\n",
        "                    outs, pres = self.forward_eval(x_batch[i_sample])\n",
        "                    d_w, d_b = self.backward_eval(outs, pres, y_batch[i_sample], x_batch[i_sample])\n",
        "                    for l_idx in range(self.total_layers):\n",
        "                        dw_acc[l_idx] += d_w[l_idx]\n",
        "                        db_acc[l_idx] += d_b[l_idx]\n",
        "\n",
        "                for l_idx in range(self.total_layers):\n",
        "                    self.W_matrices[l_idx] -= self.lr * dw_acc[l_idx] + self.weight_decay * self.W_matrices[l_idx]\n",
        "                    self.B_vectors[l_idx]  -= self.lr * db_acc[l_idx]\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def momentum_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        Momentum-based GD.\n",
        "        \"\"\"\n",
        "        vel_w = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        vel_b = [np.zeros_like(b) for b in self.B_vectors]\n",
        "        total_len = len(xT)\n",
        "\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for b_start in range(0, total_len, self.batch_size):\n",
        "                b_end = b_start + self.batch_size\n",
        "                x_batch = xT[b_start:b_end]\n",
        "                y_batch = yT[b_start:b_end]\n",
        "\n",
        "                gradW = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                gradB = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for idx in range(len(x_batch)):\n",
        "                    outs, pres = self.forward_eval(x_batch[idx])\n",
        "                    temp_w, temp_b = self.backward_eval(outs, pres, y_batch[idx], x_batch[idx])\n",
        "                    for l_idx in range(self.total_layers):\n",
        "                        gradW[l_idx] += temp_w[l_idx]\n",
        "                        gradB[l_idx] += temp_b[l_idx]\n",
        "\n",
        "                for l_idx in range(self.total_layers):\n",
        "                    vel_w[l_idx] = self.momentum_factor * vel_w[l_idx] + self.lr * gradW[l_idx]\n",
        "                    self.W_matrices[l_idx] -= vel_w[l_idx] + self.weight_decay * self.W_matrices[l_idx]\n",
        "\n",
        "                    vel_b[l_idx] = self.momentum_factor * vel_b[l_idx] + self.lr * gradB[l_idx]\n",
        "                    self.B_vectors[l_idx] -= vel_b[l_idx]\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def nesterov_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        Nesterov Accelerated Gradient.\n",
        "        \"\"\"\n",
        "        v_w = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        v_b = [np.zeros_like(b) for b in self.B_vectors]\n",
        "        length_data = len(xT)\n",
        "\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for start_idx in range(0, length_data, self.batch_size):\n",
        "                end_idx = start_idx + self.batch_size\n",
        "                subX = xT[start_idx:end_idx]\n",
        "                subY = yT[start_idx:end_idx]\n",
        "\n",
        "                # Look-ahead\n",
        "                for ly in range(self.total_layers):\n",
        "                    self.W_matrices[ly] -= self.momentum_factor * v_w[ly]\n",
        "                    self.B_vectors[ly]  -= self.momentum_factor * v_b[ly]\n",
        "\n",
        "                dw_sum = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                db_sum = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for i_samp in range(len(subX)):\n",
        "                    outs, pres = self.forward_eval(subX[i_samp])\n",
        "                    dW, dB = self.backward_eval(outs, pres, subY[i_samp], subX[i_samp])\n",
        "                    for l_idx in range(self.total_layers):\n",
        "                        dw_sum[l_idx] += dW[l_idx]\n",
        "                        db_sum[l_idx] += dB[l_idx]\n",
        "\n",
        "                for l_idx in range(self.total_layers):\n",
        "                    v_w[l_idx] = self.momentum_factor * v_w[l_idx] + self.lr * dw_sum[l_idx]\n",
        "                    self.W_matrices[l_idx] -= v_w[l_idx] + self.weight_decay * self.W_matrices[l_idx]\n",
        "\n",
        "                    v_b[l_idx] = self.momentum_factor * v_b[l_idx] + self.lr * db_sum[l_idx]\n",
        "                    self.B_vectors[l_idx] -= v_b[l_idx]\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def rmsprop_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        RMSProp optimization.\n",
        "        \"\"\"\n",
        "        accum_w = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        accum_b = [np.zeros_like(b) for b in self.B_vectors]\n",
        "        data_count = len(xT)\n",
        "\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for start_idx in range(0, data_count, self.batch_size):\n",
        "                end_idx = start_idx + self.batch_size\n",
        "                chunkX = xT[start_idx:end_idx]\n",
        "                chunkY = yT[start_idx:end_idx]\n",
        "\n",
        "                grad_wtemp = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                grad_btemp = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for i_ex in range(len(chunkX)):\n",
        "                    outs, pres = self.forward_eval(chunkX[i_ex])\n",
        "                    dw, db = self.backward_eval(outs, pres, chunkY[i_ex], chunkX[i_ex])\n",
        "                    for ly in range(self.total_layers):\n",
        "                        grad_wtemp[ly] += dw[ly]\n",
        "                        grad_btemp[ly] += db[ly]\n",
        "\n",
        "                for ly in range(self.total_layers):\n",
        "                    accum_w[ly] = self.rms_factor * accum_w[ly] + (1 - self.rms_factor) * (grad_wtemp[ly] ** 2)\n",
        "                    accum_b[ly] = self.rms_factor * accum_b[ly] + (1 - self.rms_factor) * (grad_btemp[ly] ** 2)\n",
        "\n",
        "                    self.W_matrices[ly] -= (self.lr * grad_wtemp[ly]) / (np.sqrt(accum_w[ly] + 1e-4)) \\\n",
        "                                           + self.weight_decay * self.W_matrices[ly]\n",
        "                    self.B_vectors[ly]  -= (self.lr * grad_btemp[ly]) / (np.sqrt(accum_b[ly] + 1e-4))\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def adam_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        Adam optimization.\n",
        "        \"\"\"\n",
        "        mw = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        vw = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        mb = [np.zeros_like(b) for b in self.B_vectors]\n",
        "        vb = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "        dcount = len(xT)\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for start in range(0, dcount, self.batch_size):\n",
        "                end = start + self.batch_size\n",
        "                x_part = xT[start:end]\n",
        "                y_part = yT[start:end]\n",
        "\n",
        "                stepGW = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                stepGB = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for i_samp in range(len(x_part)):\n",
        "                    outs, pres = self.forward_eval(x_part[i_samp])\n",
        "                    dW, dB = self.backward_eval(outs, pres, y_part[i_samp], x_part[i_samp])\n",
        "                    for ly in range(self.total_layers):\n",
        "                        stepGW[ly] += dW[ly]\n",
        "                        stepGB[ly] += dB[ly]\n",
        "\n",
        "                for ly in range(self.total_layers):\n",
        "                    mw[ly] = self.adam_beta1 * mw[ly] + (1 - self.adam_beta1) * stepGW[ly]\n",
        "                    vw[ly] = self.adam_beta2 * vw[ly] + (1 - self.adam_beta2) * (stepGW[ly] ** 2)\n",
        "\n",
        "                    mb[ly] = self.adam_beta1 * mb[ly] + (1 - self.adam_beta1) * stepGB[ly]\n",
        "                    vb[ly] = self.adam_beta2 * vb[ly] + (1 - self.adam_beta2) * (stepGB[ly] ** 2)\n",
        "\n",
        "                    mw_hat = mw[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    vw_hat = vw[ly] / (1 - self.adam_beta2**(ep_idx + 1))\n",
        "                    mb_hat = mb[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    vb_hat = vb[ly] / (1 - self.adam_beta2**(ep_idx + 1))\n",
        "\n",
        "                    self.W_matrices[ly] -= (self.lr * mw_hat / (np.sqrt(vw_hat) + self.epsilon_adam)) \\\n",
        "                                           + self.weight_decay * self.W_matrices[ly]\n",
        "                    self.B_vectors[ly]  -= (self.lr * mb_hat / (np.sqrt(vb_hat) + self.epsilon_adam))\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def nadam_optimizer(self, xT, yT, xV, yV):\n",
        "        \"\"\"\n",
        "        NAdam optimization (Adam + Nesterov momentum).\n",
        "        \"\"\"\n",
        "        mW = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        vW = [np.zeros_like(w) for w in self.W_matrices]\n",
        "        mB = [np.zeros_like(b) for b in self.B_vectors]\n",
        "        vB = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "        length_d = len(xT)\n",
        "        for ep_idx in range(self.epochs):\n",
        "            for start_i in range(0, length_d, self.batch_size):\n",
        "                end_i = start_i + self.batch_size\n",
        "                subX = xT[start_i:end_i]\n",
        "                subY = yT[start_i:end_i]\n",
        "\n",
        "                dw_sum = [np.zeros_like(w) for w in self.W_matrices]\n",
        "                db_sum = [np.zeros_like(b) for b in self.B_vectors]\n",
        "\n",
        "                for s_idx in range(len(subX)):\n",
        "                    outs, pres = self.forward_eval(subX[s_idx])\n",
        "                    dW, dB = self.backward_eval(outs, pres, subY[s_idx], subX[s_idx])\n",
        "                    for ly in range(self.total_layers):\n",
        "                        dw_sum[ly] += dW[ly]\n",
        "                        db_sum[ly] += dB[ly]\n",
        "\n",
        "                for ly in range(self.total_layers):\n",
        "                    mW[ly] = self.adam_beta1 * mW[ly] + (1 - self.adam_beta1) * dw_sum[ly]\n",
        "                    vW[ly] = self.adam_beta2 * vW[ly] + (1 - self.adam_beta2) * (dw_sum[ly] ** 2)\n",
        "\n",
        "                    mB[ly] = self.adam_beta1 * mB[ly] + (1 - self.adam_beta1) * db_sum[ly]\n",
        "                    vB[ly] = self.adam_beta2 * vB[ly] + (1 - self.adam_beta2) * (db_sum[ly] ** 2)\n",
        "\n",
        "                    mW_hat = mW[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    vW_hat = vW[ly] / (1 - self.adam_beta2**(ep_idx + 1))\n",
        "                    mB_hat = mB[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    vB_hat = vB[ly] / (1 - self.adam_beta2**(ep_idx + 1))\n",
        "\n",
        "                    corr_w = self.adam_beta1 * mW_hat + (1 - self.adam_beta1) * dw_sum[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    self.W_matrices[ly] -= (self.lr / (np.sqrt(vW_hat) + self.epsilon_adam)) * corr_w \\\n",
        "                                           + self.weight_decay * self.W_matrices[ly]\n",
        "\n",
        "                    corr_b = self.adam_beta1 * mB_hat + (1 - self.adam_beta1) * db_sum[ly] / (1 - self.adam_beta1**(ep_idx + 1))\n",
        "                    self.B_vectors[ly] -= (self.lr / (np.sqrt(vB_hat) + self.epsilon_adam)) * corr_b\n",
        "\n",
        "            self._track_and_log(ep_idx, xT, yT, xV, yV)\n",
        "\n",
        "    def _track_and_log(self, e_index, Xtr, Ytr, Xv, Yv):\n",
        "        \"\"\"\n",
        "        Compute/print/log train and validation metrics at certain epochs.\n",
        "        \"\"\"\n",
        "        if ((self.epochs == 10 and e_index % 2 == 1) or self.epochs == 5):\n",
        "            tr_acc, tr_loss = self._measure_metrics(Xtr, Ytr)\n",
        "            vl_acc, vl_loss = self._measure_metrics(Xv, Yv)\n",
        "            print(f\"[Epoch {e_index}] TrainAcc={tr_acc:.4f}, TrainLoss={tr_loss:.4f}, \"\n",
        "                  f\"ValAcc={vl_acc:.4f}, ValLoss={vl_loss:.4f}\")\n",
        "            wandb.log({\n",
        "                \"train_accuracy\": tr_acc,\n",
        "                \"train_loss\": tr_loss,\n",
        "                \"val_accuracy\": vl_acc,\n",
        "                \"val_loss\": vl_loss,\n",
        "                \"epoch\": e_index\n",
        "            })\n",
        "\n",
        "    def _measure_metrics(self, Xdata, Ydata):\n",
        "        \"\"\"\n",
        "        Calculates accuracy & average loss for the specified loss function.\n",
        "        \"\"\"\n",
        "        correct_sum = 0\n",
        "        total_loss = 0.0\n",
        "        small_eps = 1e-10\n",
        "        data_len = len(Xdata)\n",
        "\n",
        "        for i_eval in range(data_len):\n",
        "            layer_o, _ = self.forward_eval(Xdata[i_eval])\n",
        "            net_out = layer_o[-1]\n",
        "            best_class = np.argmax(net_out)\n",
        "            if best_class == Ydata[i_eval]:\n",
        "                correct_sum += 1\n",
        "\n",
        "            if self.loss_mech == \"cross_entropy\":\n",
        "                prob_c = max(net_out[Ydata[i_eval]][0], small_eps)\n",
        "                total_loss += -math.log10(prob_c)\n",
        "            else:\n",
        "                ideal_vec = np.zeros((self.out_features, 1))\n",
        "                ideal_vec[Ydata[i_eval]] = 1\n",
        "                total_loss += np.sum((net_out - ideal_vec) ** 2)\n",
        "\n",
        "        average_acc = correct_sum / data_len\n",
        "        average_loss = total_loss / data_len\n",
        "        return average_acc, average_loss\n",
        "\n",
        "    def plot_conf_matrix(self, x_test, y_test):\n",
        "        \"\"\"\n",
        "        Build & log a confusion matrix for test data.\n",
        "        \"\"\"\n",
        "        predictions_list = []\n",
        "        for i_t in range(len(x_test)):\n",
        "            outs, _ = self.forward_eval(x_test[i_t])\n",
        "            pred_label = np.argmax(outs[-1])\n",
        "            predictions_list.append(pred_label)\n",
        "\n",
        "        cmatrix = np.zeros((self.out_features, self.out_features))\n",
        "        for idx, real_class in enumerate(y_test):\n",
        "            predicted_class = predictions_list[idx]\n",
        "            cmatrix[real_class][predicted_class] += 1\n",
        "\n",
        "        class_names = [\n",
        "            'Ankle boot', 'T-shirt/top', 'Dress', 'Pullover',\n",
        "            'Sneaker', 'Sandal', 'Trouser', 'Shirt', 'Coat', 'Bag'\n",
        "        ]\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cmatrix, annot=True, fmt='.1f', xticklabels=class_names, yticklabels=class_names)\n",
        "        plt.title(\"Resulting Confusion Matrix\")\n",
        "        plt.xlabel(\"Predicted Category\")\n",
        "        plt.ylabel(\"Actual Category\")\n",
        "        plt.savefig(\"matrix_confusion.png\")\n",
        "        wandb.log({\"ConfusionMatrix\": wandb.Image(\"matrix_confusion.png\")})\n",
        "        plt.show()\n",
        "\n",
        "    # Activation functions & derivatives\n",
        "    def _apply_activation(self, kind, arr):\n",
        "        if kind == \"sigmoid\":\n",
        "            return self._sigmoid(arr)\n",
        "        elif kind == \"tanh\":\n",
        "            return self._tanh(arr)\n",
        "        elif kind == \"relu\":\n",
        "            return self._relu(arr)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation: {kind}\")\n",
        "\n",
        "    def _activate_derivative(self, kind, arr):\n",
        "        if kind == \"sigmoid\":\n",
        "            return self._sigmoid_deriv(arr)\n",
        "        elif kind == \"tanh\":\n",
        "            return self._tanh_deriv(arr)\n",
        "        elif kind == \"relu\":\n",
        "            return self._relu_deriv(arr)\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported activation derivative: {kind}\")\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        clipped_z = np.clip(z, -500, 500)\n",
        "        return 1.0 / (1.0 + np.exp(-clipped_z))\n",
        "\n",
        "    def _sigmoid_deriv(self, arr):\n",
        "        s_val = self._sigmoid(arr)\n",
        "        return s_val * (1 - s_val)\n",
        "\n",
        "    def _tanh(self, z):\n",
        "        clipped_z = np.clip(z, -100, 100)\n",
        "        return np.tanh(clipped_z)\n",
        "\n",
        "    def _tanh_deriv(self, arr):\n",
        "        return 1.0 - (self._tanh(arr) ** 2)\n",
        "\n",
        "    def _relu(self, z):\n",
        "        return np.maximum(0, z)\n",
        "\n",
        "    def _relu_deriv(self, arr):\n",
        "        return (arr > 0).astype(arr.dtype)\n",
        "\n",
        "    def _softmax(self, z):\n",
        "        shift_z = z - np.max(z)\n",
        "        exps = np.exp(shift_z)\n",
        "        return exps / np.sum(exps, axis=0)"
      ],
      "metadata": {
        "id": "svBQIhUmLJ7d"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# DEFAULT HYPERPARAMETERS & SWEEP CONFIG\n",
        "custom_defaults = {\n",
        "    \"epochs\": 10,\n",
        "    \"hidden_layers\": 3,\n",
        "    \"hl_size\": 128,\n",
        "    \"weight_decay\": 0,\n",
        "    \"learning_rate\": 0.0001,\n",
        "    \"optimizer\": \"nadam\",\n",
        "    \"batch_size\": 32,\n",
        "    \"initialization\": \"xavier\",\n",
        "    \"activation\": \"relu\",\n",
        "    \"loss\": \"cross_entropy\",\n",
        "    \"wandb_project\": \"DL assignment 1\",\n",
        "    \"wandb_entity\": \"\",\n",
        "    \"momentum_beta\": 0.9,\n",
        "    \"rms_beta\": 0.5,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.9,\n",
        "    \"eps\": 1e-8\n",
        "}"
      ],
      "metadata": {
        "id": "sJvS7sIZMHjw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hyper_sweep = {\n",
        "    'method': 'bayes',\n",
        "    'name': 'sweep-2',\n",
        "    'metric': {\n",
        "        'goal': 'maximize',\n",
        "        'name': 'train_accuracy',\n",
        "    },\n",
        "    'parameters': {\n",
        "        'epochs': {'values': [5, 10]},\n",
        "        'hidden_layers': {'values': [3, 4, 5]},\n",
        "        'hl_size': {'values': [32, 64, 128]},\n",
        "        'weight_decay': {'values': [0, 0.0005, 0.5]},\n",
        "        'learning_rate': {'values': [0.0001, 0.001]},\n",
        "        'optimizer': {'values': ['sgd', 'momentum', 'nestrov', 'rmsprop', 'adam', 'nadam']},\n",
        "        'batch_size': {'values': [16, 32, 64]},\n",
        "        'initialization': {'values': ['random', 'xavier']},\n",
        "        'activation': {'values': ['sigmoid', 'tanh', 'relu']},\n",
        "        'loss': {'values': ['cross_entropy']},\n",
        "        'momentum_beta': {'values': [0.9]},\n",
        "        'rms_beta': {'values': [0.5]},\n",
        "        'beta1': {'values': [0.9]},\n",
        "        'beta2': {'values': [0.9]},\n",
        "        'eps': {'values': [1e-8]},\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "b9LF1BYhMTVJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MAIN ENTRY POINT\n",
        "if __name__ == \"__main__\":\n",
        "    wandb.finish()\n",
        "\n",
        "    (train_images, train_labels), (test_images, test_labels), sample_set = acquire_fashion_mnist_data()\n",
        "\n",
        "    label_list = [\n",
        "        'Ankle boot', 'T-shirt/top', 'Dress', 'Pullover',\n",
        "        'Sneaker', 'Sandal', 'Trouser', 'Shirt', 'Coat', 'Bag'\n",
        "    ]\n",
        "    show_class_samples(sample_set, label_list)\n",
        "\n",
        "    X_train, Y_train, X_val, Y_val, X_test, Y_test = expand_flatten_normalize(\n",
        "        train_images, train_labels, test_images, test_labels\n",
        "    )\n",
        "\n",
        "    wandb.finish()\n",
        "    wandb.init(project=\"DL assignment 1\")\n",
        "\n",
        "    # Set up the sweep\n",
        "    wandb.finish()\n",
        "    sweep_key = wandb.sweep(sweep=hyper_sweep, project=\"DL assignment 1\")\n",
        "    print(\"Sweep ID:\", sweep_key)\n",
        "\n",
        "    def run_sweep_experiment():\n",
        "        wandb.finish()\n",
        "        run_in = wandb.init(project=\"DL assignment 1\")\n",
        "        config_used = wandb.config\n",
        "        print(\"Running with configuration:\", config_used)\n",
        "\n",
        "        netz = FullyConnectedNet(784, 10, config_used)\n",
        "        netz.training(X_train, Y_train, X_val, Y_val)\n",
        "        # Possibly do netz.plot_conf_matrix(X_test, Y_test) here\n",
        "\n",
        "    wandb.agent(sweep_key, function=run_sweep_experiment, count=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lZ-g-9vbMKfZ",
        "outputId": "d1de2d07-c9a5-45e7-d2cf-73f160c1c6bf"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "Abort",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAbort\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-ec961a9084d2>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;34m'Sneaker'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Sandal'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Trouser'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Shirt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Coat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Bag'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     ]\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mshow_class_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     X_train, Y_train, X_val, Y_val, X_test, Y_test = expand_flatten_normalize(\n",
            "\u001b[0;32m<ipython-input-4-e6e11b169f6a>\u001b[0m in \u001b[0;36mshow_class_samples\u001b[0;34m(sample_pics, label_names)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class_examples.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'DL assignment 1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"sample_images\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'class_examples.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mlogin\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \"\"\"\n\u001b[1;32m     75\u001b[0m     \u001b[0m_handle_host_wandb_setting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     return _login(\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0manonymous\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0manonymous\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_login\u001b[0;34m(anonymous, key, relogin, host, force, timeout, verify, _silent, _disable_warning)\u001b[0m\n\u001b[1;32m    303\u001b[0m             \u001b[0mkey_is_pre_configured\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey_status\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwlogin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mprompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;34m\"\"\"Updates the global API key by prompting the user.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 227\u001b[0;31m         \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prompt_api_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    228\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mApiKeyStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m             directive = (\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/wandb_login.py\u001b[0m in \u001b[0;36m_prompt_api_key\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 key = apikey.prompt_api_key(\n\u001b[0m\u001b[1;32m    207\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_settings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                     \u001b[0mapi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/wandb/sdk/lib/apikey.py\u001b[0m in \u001b[0;36mprompt_api_key\u001b[0;34m(settings, api, input_callback, browser_callback, no_offline, no_create, local)\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;34mf\"You can find your API key in your browser here: {app_url}/authorize\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m             )\n\u001b[0;32m--> 171\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapi_ask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mLOGIN_CHOICE_NOTTY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0;31m# TODO: Needs refactor as this needs to be handled by caller\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt\u001b[0;34m(text, default, hide_input, confirmation_prompt, type, value_proc, prompt_suffix, show_default, err, show_choices)\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprompt_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/click/termui.py\u001b[0m in \u001b[0;36mprompt_func\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhide_input\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mecho\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAbort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mvalue_proc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAbort\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DOpLaGXxNNr7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}